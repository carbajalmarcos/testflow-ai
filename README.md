<div align="center">

# ğŸ§ª testflow-ai

**Declarative API testing powered by YAML flows**

*Version-controlled â€¢ Human-readable â€¢ AI-friendly*

[![npm version](https://img.shields.io/npm/v/testflow-ai.svg?style=for-the-badge&color=blue)](https://www.npmjs.com/package/testflow-ai)
[![npm downloads](https://img.shields.io/npm/dm/testflow-ai.svg?style=for-the-badge&color=green)](https://www.npmjs.com/package/testflow-ai)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Node.js](https://img.shields.io/badge/node-%3E%3D18-green.svg?style=for-the-badge)](https://nodejs.org)

[ğŸ“– Documentation](#-documentation) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ’» Examples](#-real-world-example) â€¢ [ğŸ¤– AI Providers](#-ai-powered-evaluation)

</div>

---

## ğŸ¯ What is testflow-ai?

**testflow-ai** lets you define API tests in YAML files, run them from the command line or as a library, and use AI models (local or cloud) for intelligent assertions. No GUI, no vendor lock-in, works with any HTTP/GraphQL API.

> **ğŸ’¡ Born from real-world frustration:** After months of testing APIs with Postman and burning tokens with ChatGPT, I built this to centralize tests in version-controlled YAML files with local AI support.

### âœ¨ Key Features

<div align="center">

| ğŸ¨ Feature | ğŸ“ Description |
|:----------:|:-------------:|
| **ğŸ“ YAML Flows** | Define test sequences declaratively â€” version-controlled and human-readable |
| **ğŸ”— Variable Capture** | Extract values from responses, reuse in later steps automatically |
| **âœ… Rich Assertions** | 10+ operators: equals, contains, exists, greaterThan, matches, and more |
| **ğŸ”„ GraphQL Native** | First-class support for queries and mutations |
| **â³ Async Polling** | `waitUntil` for operations that take time (background jobs, processing) |
| **ğŸ¤– AI Evaluation** | Assert with natural language using Ollama, OpenAI, or Anthropic |
| **ğŸ“„ Context Files** | Define base URLs, endpoints, and rules in Markdown |
| **ğŸ“Š Multiple Formats** | Console (colored), JSON (CI/CD), or Markdown reports |
| **ğŸ¯ Tag Filtering** | Run subsets of your test suite (`--tags smoke,e2e`) |
| **ğŸ–¥ï¸ CLI + API** | Use from terminal (`npx testflow`) or import as a library |

</div>

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Install

```bash
npm install testflow-ai
```

### 2ï¸âƒ£ Create a test flow

Create `tests/health.yaml`:

```yaml
name: Health Check
tags: [smoke]

steps:
  - name: Ping API
    request:
      method: GET
      url: http://localhost:3000/health
    assertions:
      - path: status
        operator: equals
        value: 200
```

### 3ï¸âƒ£ Run

```bash
npx testflow tests/health.yaml
```

**That's it.** No config files, no GUI, no account.

---

## ğŸ’¡ Why testflow-ai?

I was building a backend that started as a simple API and grew into a system with GraphQL, async workers, state machines, and AI-powered evaluations.

Testing started simple â€” a few requests in Postman. Then the project scaled:

<div align="center">

| âŒ Problem | âœ… Solution |
|:----------:|:-----------:|
| **Postman / Insomnia** became unmanageable | YAML files in version control |
| **IDE AI assistants** burned tokens, lost context | Local AI via Ollama (free, private) |
| **MCP servers** required complex setup | Zero dependencies beyond Node.js |
| **Manual token copying** between requests | Automatic variable capture |
| **No CI/CD integration** | JSON output, exit codes, GitHub Actions ready |

</div>

**testflow-ai** solves all of this.

---

## ğŸ“¦ Installation

```bash
npm install testflow-ai
# or
pnpm add testflow-ai
# or
yarn add testflow-ai
```

---

## ğŸ–¥ï¸ CLI Usage

```bash
# Run specific files
npx testflow flow1.yaml flow2.yaml

# Run all YAML files in a directory
npx testflow --dir ./tests

# Use a context file for base URLs
npx testflow --dir ./tests --context ./context.md

# Filter by tags (run only smoke tests)
npx testflow --dir ./tests --tags smoke

# JSON output (for CI/CD)
npx testflow --dir ./tests --format json

# Markdown output (for reports)
npx testflow --dir ./tests --format markdown

# Verbose mode (see step-by-step execution)
npx testflow --dir ./tests -v

# With AI evaluation
npx testflow --dir ./tests --ai-provider ollama --ai-model llama3.2:3b
npx testflow --dir ./tests --ai-provider openai --ai-key $OPENAI_API_KEY --ai-model gpt-4o-mini
```

---

## ğŸ’» Programmatic API

### Simple usage

```typescript
import { runTests } from 'testflow-ai';

const report = await runTests({
  contextFile: './context.md',
  testDir: './tests',
  tags: ['smoke'],
  format: 'console',
  verbose: true,
});

console.log(`${report.passedFlows}/${report.totalFlows} passed`);
process.exit(report.failedFlows > 0 ? 1 : 0);
```

---

## ğŸ’» Real-World Example

Here's how we use it in production at [educational-rewards](https://github.com/carbajalmarcos/educational-rewards):

### Project Structure

```
tests/declarative/
â”œâ”€â”€ index.ts              # Test runner
â”œâ”€â”€ context.md            # API context
â””â”€â”€ flows/
    â”œâ”€â”€ health-check.yaml
    â”œâ”€â”€ complete-reward-flow.yaml
    â””â”€â”€ submission-attempts.yaml
```

### Test Runner (`index.ts`)

```typescript
import { runTests, type RunnerOptions } from 'testflow-ai';
import * as path from 'path';

async function main() {
  const options: RunnerOptions = {
    contextFile: path.join(__dirname, 'context.md'),
    testDir: path.join(__dirname, 'flows'),
    tags: process.argv.includes('--tags=smoke') ? ['smoke'] : undefined,
    format: 'console',
    verbose: false,
  };

  const report = await runTests(options);
  process.exit(report.failedFlows > 0 ? 1 : 0);
}

main();
```

### Context File (`context.md`)

```markdown
# Mambita API Context

## Base URLs
- graphql: http://localhost:3000/graphql
- tasks: http://localhost:8000

## Endpoints
- POST /graphql - GraphQL endpoint
- POST /api/v1/pool/seed - Seed task pool
```

### Test Flow (`flows/complete-reward-flow.yaml`)

```yaml
name: Complete Reward Flow (E2E)
tags: [e2e, reward]

steps:
  - name: Start reward
    request:
      method: POST
      url: "{graphql}"
      graphql:
        query: |
          mutation StartReward($input: StartRewardInput!) {
            startReward(input: $input) {
              id
              state
              taskInstances { id state }
            }
          }
        variables:
          input:
            childId: "${childId}"
            catalogRewardId: "${catalogItemId}"
    capture:
      - name: rewardId
        path: data.startReward.id
```

### Running Tests

```bash
pnpm testflow:run              # All tests
pnpm testflow:smoke            # Smoke tests only
pnpm testflow submission-attempts  # Specific flow
```

### Advanced usage

```typescript
import { TestRunner, FlowExecutor, parseYamlFile, parseContextFile } from 'testflow-ai';

// Runner with full control
const runner = new TestRunner({
  contextFile: './context.md',
  testFiles: ['./tests/critical.yaml'],
  ai: { provider: 'ollama', model: 'mistral:7b' },
});
const report = await runner.run();

// Manual execution
const context = await parseContextFile('./context.md');
const flow = await parseYamlFile('./tests/flow.yaml');
const executor = new FlowExecutor(context, true);
const result = await executor.executeFlow(flow);
```

---

## ğŸ“ Test Flow Reference

### Basic structure

```yaml
name: User Registration Flow
description: Create and verify a new user
tags:
  - users
  - smoke

steps:
  - name: Create user
    request:
      method: POST
      url: "{api}/users"
      headers:
        Content-Type: application/json
      body:
        email: alice@example.com
        name: Alice
    capture:
      - name: userId
        path: data.id
    assertions:
      - path: status
        operator: equals
        value: 201
      - path: data.email
        operator: equals
        value: alice@example.com

  - name: Verify user
    request:
      method: GET
      url: "{api}/users/${userId}"
    assertions:
      - path: data.id
        operator: equals
        value: "${userId}"
```

### GraphQL requests

```yaml
steps:
  - name: Query user
    request:
      method: POST
      url: "{graphql}"
      graphql:
        query: |
          query GetUser($id: ID!) {
            user(id: $id) {
              id
              email
              name
            }
          }
        variables:
          id: "${userId}"
    capture:
      - name: userEmail
        path: data.user.email
```

### Variable capture and interpolation

Variables captured in one step are available in all subsequent steps:

```yaml
steps:
  - name: Login
    request:
      method: POST
      url: "{api}/auth/login"
      body:
        email: admin@example.com
        password: secret
    capture:
      - name: token
        path: data.accessToken
      - name: userId
        path: data.user.id

  - name: Get profile
    request:
      method: GET
      url: "{api}/users/${userId}"
      headers:
        Authorization: "Bearer ${token}"
```

**Supported patterns:**

- `${variable}` â€” simple variable
- `${data.nested.field}` â€” nested path
- `${items[0].id}` â€” array access

### Async polling (waitUntil)

For operations that take time â€” polls until condition is met or timeout:

```yaml
steps:
  - name: Wait for job completion
    request:
      method: GET
      url: "{api}/jobs/${jobId}"
    waitUntil:
      path: data.status
      operator: equals
      value: "COMPLETED"
      timeout: 30000    # max wait (ms)
      interval: 2000    # poll every (ms)
    assertions:
      - path: data.status
        operator: equals
        value: "COMPLETED"
```

---

## âœ… Assertions

<div align="center">

| Operator | Description | Example |
|:--------:|:-----------:|:-------:|
| `equals` | Exact match (deep equality) | `value: 200` |
| `notEquals` | Not equal | `value: null` |
| `contains` | String/array contains | `value: "success"` |
| `notContains` | Does not contain | `value: "error"` |
| `exists` | Not null/undefined | â€” |
| `notExists` | Is null/undefined | â€” |
| `greaterThan` | Number comparison | `value: 0` |
| `lessThan` | Number comparison | `value: 100` |
| `matches` | Regex match | `value: "^[a-z]+$"` |
| `ai-evaluate` | AI-powered evaluation | `value: "Is this valid?"` |

</div>

**Special paths:**

- `status` â€” HTTP status code (when value is a number)
- `httpStatus` â€” always the HTTP status code
- `data.field` â€” response body field
- `data.items[0].id` â€” array access

---

## ğŸ¤– AI-Powered Evaluation

Use AI to assert things that are hard to express with traditional operators. **testflow-ai** supports multiple providers:

<div align="center">

| Provider | Type | Setup | Best For |
|:--------:|:----:|:-----:|:--------:|
| **ğŸ¦™ Ollama** | Local | Free, no API key | Privacy, offline, cost-effective |
| **ğŸ¤– OpenAI** | Cloud | API key required | High accuracy, GPT-4 |
| **ğŸ§  Anthropic** | Cloud | API key required | Claude models, safety-focused |

</div>

### ğŸ¦™ Ollama (Local, Recommended)

**No cloud API keys, no data leaves your machine.**

1. **Install Ollama** â€” [ollama.com/download](https://ollama.com/download)

2. **Pull a model:**

```bash
# Recommended â€” good balance of speed and quality
ollama pull llama3.2:3b

# Faster, lighter (for limited hardware)
ollama pull llama3.2:1b

# More accurate (needs ~8GB RAM)
ollama pull mistral:7b
```

1. **Start Ollama** (runs on `http://localhost:11434` by default):

```bash
ollama serve
```

**Usage:**

```bash
# CLI
npx testflow --dir ./tests --ai-provider ollama --ai-model llama3.2:3b

# Programmatic
const report = await runTests({
  testDir: './tests',
  ai: {
    provider: 'ollama',
    url: 'http://localhost:11434',
    model: 'llama3.2:3b',
  },
});
```

### ğŸ¤– OpenAI (Cloud)

**Requires API key from [platform.openai.com](https://platform.openai.com/api-keys)**

```bash
# CLI
npx testflow --dir ./tests \
  --ai-provider openai \
  --ai-key $OPENAI_API_KEY \
  --ai-model gpt-4o-mini

# Programmatic
const report = await runTests({
  testDir: './tests',
  ai: {
    provider: 'openai',
    apiKey: process.env.OPENAI_API_KEY,
    model: 'gpt-4o-mini',
  },
});
```

**Supported models:** `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-3.5-turbo`

### ğŸ§  Anthropic (Cloud)

**Requires API key from [console.anthropic.com](https://console.anthropic.com/)**

```bash
# CLI
npx testflow --dir ./tests \
  --ai-provider anthropic \
  --ai-key $ANTHROPIC_API_KEY \
  --ai-model claude-3-haiku-20240307

# Programmatic
const report = await runTests({
  testDir: './tests',
  ai: {
    provider: 'anthropic',
    apiKey: process.env.ANTHROPIC_API_KEY,
    model: 'claude-3-haiku-20240307',
  },
});
```

**Supported models:** `claude-3-5-sonnet-20241022`, `claude-3-opus-20240229`, `claude-3-haiku-20240307`

### Using AI assertions

```yaml
steps:
  - name: Check article quality
    request:
      method: GET
      url: "{api}/articles/1"
    assertions:
      # Traditional assertion
      - path: status
        operator: equals
        value: 200
      # AI-powered assertion (works with any provider)
      - path: data.content
        operator: ai-evaluate
        value: "Does this article contain a coherent explanation with at least two paragraphs?"
```

### Context file AI config

```markdown
## AI Configuration
- provider: ollama
- url: http://localhost:11434
- model: llama3.2:3b

# Or for cloud providers:
# provider: openai
# apiKey: ${OPENAI_API_KEY}
# model: gpt-4o-mini
```

> **ğŸ”’ Privacy note:** Ollama runs entirely locally. OpenAI and Anthropic send data to their APIs. Choose based on your privacy requirements.

---

## ğŸ“„ Context Files

Define your project context in Markdown. The runner uses it to resolve `{baseUrlKey}` references in your YAML flows.

```markdown
# My API

## Description
Brief description of your API.

## Base URLs
- api: http://localhost:3000
- graphql: http://localhost:3000/graphql

## Endpoints
- POST /users - Create user
- GET /users/:id - Get user
- POST /graphql - GraphQL endpoint

## Rules
- All endpoints return JSON
- Authentication required for /users

## AI Configuration
- provider: ollama
- url: http://localhost:11434
- model: llama3.2:3b
```

---

## ğŸ”„ CI/CD Integration

### GitHub Actions

```yaml
jobs:
  api-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      - run: npm ci
      - run: npm run start:server &
      - run: npx testflow --dir ./tests --context ./context.md --format json > results.json
      - uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: results.json
```

**Exit codes:**

- `0` â€” all flows passed
- `1` â€” one or more flows failed

---

## ğŸ“Š Output Examples

### Console Output

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  TESTFLOW AI â€” RESULTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Summary:
  Total:    5 flows
  Passed:  5
  Failed:  0
  Duration: 2450ms

Narrative:

âœ… **User CRUD**
   â†’ Create user
     ğŸ“¦ userId: abc-123
   â†’ Read user
   â†’ Update user

âœ… **Auth Flow**
   â†’ Login
     ğŸ“¦ token: eyJhbGâ€¦
   â†’ Access protected route

âŒ **Payment Flow**
   âœ— Create payment
     âš ï¸  Expected status to equal 200, got 500

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ—ºï¸ Roadmap

- [ ] Database assertions (verify records directly via SQL)
- [ ] gRPC / RPC support
- [ ] OpenAPI spec â†’ auto-generate test flows
- [ ] Watch mode (re-run on file change)
- [ ] Parallel flow execution
- [ ] HTML report output
- [ ] `testflow init` wizard

---

## ğŸ“š Examples

See the [`examples/`](./examples) directory for:

- REST CRUD flows
- GraphQL queries and mutations
- Authentication flows
- Context file templates

---

## ğŸ“„ License

MIT

---

<div align="center">

**Made with â¤ï¸ by [Marcos Carbajal](https://github.com/carbajalmarcos)**

[â­ Star on GitHub](https://github.com/carbajalmarcos/testflow-ai) â€¢ [ğŸ“¦ npm](https://www.npmjs.com/package/testflow-ai) â€¢ [ğŸ› Report Bug](https://github.com/carbajalmarcos/testflow-ai/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/carbajalmarcos/testflow-ai/discussions)

---

### â˜• Support this project

If you find **testflow-ai** useful, consider supporting its development:

[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://buymeacoffee.com/carbajalmarcos)
[![GitHub Sponsors](https://img.shields.io/badge/GitHub%20Sponsors-ea4aaa?style=for-the-badge&logo=github&logoColor=white)](https://github.com/sponsors/carbajalmarcos)
[![Ko-fi](https://img.shields.io/badge/Ko--fi-F16061?style=for-the-badge&logo=ko-fi&logoColor=white)](https://ko-fi.com/carbajalmarcos)

**Crypto donations:**

- **Bitcoin (BTC):** `bc1qv0ddjg3wcgujk9ad66v9msz8manu5tanhvq0fn`
- **ERC-20 USDT:** `0x79F57C9D45d2D40420EF071DDAaA27057618E7C8`

*Every contribution helps make this project better!*

</div>
